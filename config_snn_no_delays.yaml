################################################
#            Common configuration             #
################################################

seed: 0  # Seed for random number generation

time_step: 16  # Time step for simulation in ms
batch_size: 4  # Batch size for training

n_hidden_layers: 5  # Number of hidden layers in the neural network
n_hidden_neurons: 128  # Number of neurons in each hidden layer

# data related parameters
n_inputs: 2  # Number of input features
n_outputs: 11  # Number of output classes
height: 128  # Height of the input images or feature map
width: 128  # Width of the input images or feature map

init_tau: 2.0  # Initial membrane time constant (tau) (*time_step)

use_maxpool: true  # Whether to use max pooling in the network
use_batchnorm: true  # Whether to use batch normalization
bias: false  # Whether to include bias terms in the model
detach_reset: true  # Whether to detach the reset from backpropagation (for stability)

output_v_threshold: 1e9  # Voltage threshold for output neurons (extremely high value)

v_threshold: 1.0  # Threshold for neuron voltage to trigger a spike
alpha: 2.0  # Alpha value for the surrogate activation function

init_w_method: 'kaiming_uniform'  # Initialization method for weights

################################################
#               Optimizer hyperparameters      #
################################################

lr_w: 0.001  # Learning rate for weight parameters
weight_decay: 1e-5  # Weight decay (L2 regularization)
dropout_p: 0.25  # Dropout probability for regularization
